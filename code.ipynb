{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai==0.28\n",
    "# %pip install \"weaviate-client==3.*\"\n",
    "# %pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import weaviate\n",
    "env_vars = {\n",
    "    \"OPENAI_API_KEY\" : \"\",\n",
    "    \"WEAVIATE_API_KEY\" : \"\"\n",
    "}\n",
    "openai.api_key = env_vars['OPENAI_API_KEY']\n",
    "auth_config = weaviate.auth.AuthApiKey(\n",
    "    api_key= env_vars['WEAVIATE_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hlo\\venv\\lib\\site-packages\\weaviate\\warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.2. The latest version is 4.4.4.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "weaviate_client = weaviate.Client(\n",
    "    url = \"https://tashu-ikyhn3en.weaviate.network\",\n",
    "    auth_client_secret=auth_config,\n",
    "    additional_headers={\"X-OpenAI-Api-Key\": env_vars['OPENAI_API_KEY']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Hello, how can I help you today?\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "def openai_chat_completion(messages):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    response = completion.choices[0].message['content']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "def load_json_file(filename):\n",
    "    with open(filename) as f:\n",
    "        file = json.load(f)\n",
    "    return file\n",
    "filename = 'intents.json'\n",
    "json_file = load_json_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Hi</td>\n",
       "      <td>Hello!, Good to see you again!, Hi there, how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greeting</td>\n",
       "      <td>How are you?</td>\n",
       "      <td>Hello!, Good to see you again!, Hi there, how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Is anyone there?</td>\n",
       "      <td>Hello!, Good to see you again!, Hi there, how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Hello!, Good to see you again!, Hi there, how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Good day</td>\n",
       "      <td>Hello!, Good to see you again!, Hi there, how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>ragging</td>\n",
       "      <td>ragging history</td>\n",
       "      <td>We are Proud to tell you that our college prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>ragging</td>\n",
       "      <td>ragging incidents</td>\n",
       "      <td>We are Proud to tell you that our college prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>hod</td>\n",
       "      <td>hod</td>\n",
       "      <td>HODs differ for each branch, please be more sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>hod</td>\n",
       "      <td>hod name</td>\n",
       "      <td>HODs differ for each branch, please be more sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>hod</td>\n",
       "      <td>who is the hod</td>\n",
       "      <td>HODs differ for each branch, please be more sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tag            Pattern  \\\n",
       "0    greeting                 Hi   \n",
       "1    greeting       How are you?   \n",
       "2    greeting   Is anyone there?   \n",
       "3    greeting              Hello   \n",
       "4    greeting           Good day   \n",
       "..        ...                ...   \n",
       "400   ragging    ragging history   \n",
       "401   ragging  ragging incidents   \n",
       "402       hod                hod   \n",
       "403       hod           hod name   \n",
       "404       hod     who is the hod   \n",
       "\n",
       "                                              Response  \n",
       "0    Hello!, Good to see you again!, Hi there, how ...  \n",
       "1    Hello!, Good to see you again!, Hi there, how ...  \n",
       "2    Hello!, Good to see you again!, Hi there, how ...  \n",
       "3    Hello!, Good to see you again!, Hi there, how ...  \n",
       "4    Hello!, Good to see you again!, Hi there, how ...  \n",
       "..                                                 ...  \n",
       "400  We are Proud to tell you that our college prov...  \n",
       "401  We are Proud to tell you that our college prov...  \n",
       "402  HODs differ for each branch, please be more sp...  \n",
       "403  HODs differ for each branch, please be more sp...  \n",
       "404  HODs differ for each branch, please be more sp...  \n",
       "\n",
       "[405 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "tag_list = []\n",
    "pattern_list = []\n",
    "response_list = []\n",
    "intents = json_file['intents']\n",
    "for intent in intents:\n",
    "    tag = intent[\"tag\"]\n",
    "    patterns = intent[\"patterns\"]\n",
    "    responses = intent[\"responses\"]\n",
    "    for pattern in patterns:\n",
    "        tag_list.append(tag)\n",
    "        pattern_list.append(pattern)\n",
    "        response_list.append(', '.join(responses))\n",
    "dic = {\n",
    "    \"Tag\": tag_list,\n",
    "    \"Pattern\": pattern_list,\n",
    "    \"Response\": response_list\n",
    "}\n",
    "df = pd.DataFrame(dic)\n",
    "df.to_csv(\"data.csv\",index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "loader = CSVLoader('data.csv')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key = env_vars['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hlo\\venv\\lib\\site-packages\\pydantic\\main.py:1024: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Weaviate\n",
    "vectorstore = Weaviate.from_documents(data, embeddings, client = weaviate_client, by_text= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(openai_api_key= env_vars['OPENAI_API_KEY'],temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "    Use the dataset {data} and generate as many as possible questions with answers. Answers about application deadlines, required documents, tuition fees, scholarship opportunities. Don't try to make up question answers on your own that are not in the datset. keep the answer as concise as possible.\n",
    "\"\"\"\n",
    "template = \"\"\"Use the following pieces of context to answer the question. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use fifty words maximum. Keep the answer as concise as possible.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=vectorstore.as_retriever(search_type = \"mmr\"),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "def generate(question):\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    P, R, F1 = score([result['result']], [question], lang=\"en\", verbose=False)\n",
    "    return result['result'], f\"Precision: {P.mean()}\\nRecall: {R.mean()}\\nF1: {F1.mean()}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hlo\\venv\\lib\\site-packages\\gradio\\routes.py:816: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  @app.on_event(\"startup\")\n",
      "c:\\Users\\Hlo\\venv\\lib\\site-packages\\fastapi\\applications.py:4495: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  return self.router.on_event(event_type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hlo\\venv\\lib\\site-packages\\starlette\\templating.py:172: DeprecationWarning: The `name` is not the first parameter anymore. The first parameter should be the `Request` instance.\n",
      "Replace `TemplateResponse(name, {\"request\": request})` by `TemplateResponse(request, name)`.\n",
      "  warnings.warn(\n",
      "Exception in thread Thread-17 (_do_normal_analytics_request):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpcore\\_exceptions.py\", line 10, in map_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpcore\\_backends\\sync.py\", line 206, in connect_tcp\n",
      "    sock = socket.create_connection(\n",
      "  File \"C:\\Users\\Hlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py\", line 845, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\Hlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py\", line 833, in create_connection\n",
      "    sock.connect(sa)\n",
      "TimeoutError: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 67, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 231, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 268, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 251, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpcore\\_sync\\connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpcore\\_sync\\connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpcore\\_backends\\sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"C:\\Users\\Hlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\Hlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\gradio\\analytics.py\", line 63, in _do_normal_analytics_request\n",
      "    httpx.post(url, data=data, timeout=5)\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpx\\_api.py\", line 317, in post\n",
      "    return request(\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpx\\_api.py\", line 104, in request\n",
      "    return client.request(\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpx\\_client.py\", line 828, in request\n",
      "    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpx\\_client.py\", line 915, in send\n",
      "    response = self._send_handling_auth(\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpx\\_client.py\", line 943, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpx\\_client.py\", line 980, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1016, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 230, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"C:\\Users\\Hlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\Hlo\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 84, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectTimeout: timed out\n",
      "c:\\Users\\Hlo\\venv\\lib\\site-packages\\pydantic\\main.py:1024: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "c:\\Users\\Hlo\\venv\\lib\\site-packages\\pydantic\\main.py:1024: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Hlo\\venv\\lib\\site-packages\\pydantic\\main.py:1024: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "c:\\Users\\Hlo\\venv\\lib\\site-packages\\pydantic\\main.py:1024: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "demo = gr.Interface(fn=generate, \n",
    "                    inputs=[gr.Textbox(label=\"You\")],\n",
    "                    outputs=[gr.Textbox(label=\"Bot\")],\n",
    "                    title=\"FAQ Chatbot\",\n",
    "                    description=\"Answers about application deadlines, required documents, tuition fees, scholarship opportunities, etc. Ask your questions and get instant answers!\"\n",
    ")\n",
    "\n",
    "gr.close_all()\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
