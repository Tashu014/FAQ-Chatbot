{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai==0.28\n",
    "# %pip install \"weaviate-client==3.*\"\n",
    "# %pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import weaviate\n",
    "env_vars = {\n",
    "    \"OPENAI_API_KEY\" : \"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\",\n",
    "    \"WEAVIATE_API_KEY\" : \"qv1u9FCytBmtQmya3bfHyG8Camj6FlGYpBEN\"\n",
    "}\n",
    "openai.api_key = env_vars['OPENAI_API_KEY']\n",
    "auth_config = weaviate.auth.AuthApiKey(\n",
    "    api_key= env_vars['WEAVIATE_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate_client = weaviate.Client(\n",
    "    url = \"https://assignment0202-6onvs3cy.weaviate.network\",\n",
    "    auth_client_secret=auth_config,\n",
    "    additional_headers={\"X-OpenAI-Api-Key\": env_vars['OPENAI_API_KEY']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Hello, how can I help you today?\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "def openai_chat_completion(messages, slider):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        max_new_tokens = slider,\n",
    "        temperature=0, \n",
    "    )\n",
    "    response = completion.choices[0].message['content']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "def load_json_file(filename):\n",
    "    with open(filename) as f:\n",
    "        file = json.load(f)\n",
    "    return file\n",
    "filename = 'intents.json'\n",
    "json_file = load_json_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Hi</td>\n",
       "      <td>Hello!, Good to see you again!, Hi there, how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greeting</td>\n",
       "      <td>How are you?</td>\n",
       "      <td>Hello!, Good to see you again!, Hi there, how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Is anyone there?</td>\n",
       "      <td>Hello!, Good to see you again!, Hi there, how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Hello!, Good to see you again!, Hi there, how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Good day</td>\n",
       "      <td>Hello!, Good to see you again!, Hi there, how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>ragging</td>\n",
       "      <td>ragging history</td>\n",
       "      <td>We are Proud to tell you that our college prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>ragging</td>\n",
       "      <td>ragging incidents</td>\n",
       "      <td>We are Proud to tell you that our college prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>hod</td>\n",
       "      <td>hod</td>\n",
       "      <td>HODs differ for each branch, please be more sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>hod</td>\n",
       "      <td>hod name</td>\n",
       "      <td>HODs differ for each branch, please be more sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>hod</td>\n",
       "      <td>who is the hod</td>\n",
       "      <td>HODs differ for each branch, please be more sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tag            Pattern  \\\n",
       "0    greeting                 Hi   \n",
       "1    greeting       How are you?   \n",
       "2    greeting   Is anyone there?   \n",
       "3    greeting              Hello   \n",
       "4    greeting           Good day   \n",
       "..        ...                ...   \n",
       "400   ragging    ragging history   \n",
       "401   ragging  ragging incidents   \n",
       "402       hod                hod   \n",
       "403       hod           hod name   \n",
       "404       hod     who is the hod   \n",
       "\n",
       "                                              Response  \n",
       "0    Hello!, Good to see you again!, Hi there, how ...  \n",
       "1    Hello!, Good to see you again!, Hi there, how ...  \n",
       "2    Hello!, Good to see you again!, Hi there, how ...  \n",
       "3    Hello!, Good to see you again!, Hi there, how ...  \n",
       "4    Hello!, Good to see you again!, Hi there, how ...  \n",
       "..                                                 ...  \n",
       "400  We are Proud to tell you that our college prov...  \n",
       "401  We are Proud to tell you that our college prov...  \n",
       "402  HODs differ for each branch, please be more sp...  \n",
       "403  HODs differ for each branch, please be more sp...  \n",
       "404  HODs differ for each branch, please be more sp...  \n",
       "\n",
       "[405 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "tag_list = []\n",
    "pattern_list = []\n",
    "response_list = []\n",
    "intents = json_file['intents']\n",
    "for intent in intents:\n",
    "    tag = intent[\"tag\"]\n",
    "    patterns = intent[\"patterns\"]\n",
    "    responses = intent[\"responses\"]\n",
    "    for pattern in patterns:\n",
    "        tag_list.append(tag)\n",
    "        pattern_list.append(pattern)\n",
    "        response_list.append(', '.join(responses))\n",
    "dic = {\n",
    "    \"Tag\": tag_list,\n",
    "    \"Pattern\": pattern_list,\n",
    "    \"Response\": response_list\n",
    "}\n",
    "df = pd.DataFrame(dic)\n",
    "df.to_csv(\"data.csv\",index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "loader = CSVLoader('data.csv')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key = env_vars['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Weaviate\n",
    "vectorstore = Weaviate.from_documents(data, embeddings, client = weaviate_client, by_text= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(openai_api_key= env_vars['OPENAI_API_KEY'],temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "    Use the dataset {data} and generate as many as possible questions with answers. Answers about application deadlines, required documents, tuition fees, scholarship opportunities. Don't try to make up question answers on your own that are not in the datset. keep the answer as concise as possible.\n",
    "\"\"\"\n",
    "template = \"\"\"Use the following pieces of context to answer the question. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use fifty words maximum. Keep the answer as concise as possible.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=vectorstore.as_retriever(search_type = \"mmr\"),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(question, slider):\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    P, R, F1 = score([result['result']], [question], lang=\"en\", verbose=True)\n",
    "    return result, f\"Precision: {P.mean()}\\nRecall: {R.mean()}\\nF1: {F1.mean()}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53aced0fee4a4e76bbddc91eab5f1749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c227477f98447ba9a3db16538cc7564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.10 seconds, 0.91 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "demo = gr.Interface(fn=generate, \n",
    "                    inputs=[gr.Textbox(label=\"Prompt\"), \n",
    "                            gr.Slider(label=\"Max new tokens\", \n",
    "                                      value=20,  \n",
    "                                      maximum=1024, \n",
    "                                      minimum=1)], \n",
    "                    outputs=[gr.Textbox(label=\"Completion\")])\n",
    "\n",
    "gr.close_all()\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
